{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c22093a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import ElectraTokenizer, ElectraForSequenceClassification\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import time, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9110a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet(\"./dataset_grammar.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af586ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(index=data.index[data.Rating==2])\n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0c73747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    388281\n",
       "0     70926\n",
       "Name: Rating, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cf9c0e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    459207.000000\n",
       "mean        138.518812\n",
       "std         188.789379\n",
       "min           0.000000\n",
       "25%          39.000000\n",
       "50%          76.000000\n",
       "75%         164.000000\n",
       "max        3971.000000\n",
       "Name: Review, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Review.str.len().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24100b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at monologg/koelectra-base-v3-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "tokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-base-v3-discriminator\")\n",
    "#model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased')\n",
    "model = ElectraForSequenceClassification.from_pretrained('monologg/koelectra-base-v3-discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dde7398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizer(name_or_path='monologg/koelectra-base-v3-discriminator', vocab_size=35000, model_max_len=512, is_fast=False, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c0c3242",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data = train_test_split(data, shuffle=True, stratify=data.Rating, random_state=217, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47362b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data, test_data = train_test_split(valid_data, stratify=valid_data.Rating, random_state=217, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa8384f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((367365, 2), (45921, 2), (45921, 2))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, valid_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62974d54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 56741, 310624]), array([ 7092, 38829]), array([ 7093, 38828]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(train_data.Rating), np.bincount(valid_data.Rating), np.bincount(test_data.Rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d20eba8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def electra_tokenizer(sent, MAX_LEN):\n",
    "    encoded_dict = tokenizer.encode_plus(text = sent, add_special_tokens=True, max_length=MAX_LEN, padding='max_length', return_attention_mask=True, truncation=True)\n",
    "    \n",
    "    input_ids = encoded_dict['input_ids']\n",
    "    attention_masks = encoded_dict['attention_mask']\n",
    "    token_type_ids = encoded_dict['token_type_ids']\n",
    "    \n",
    "    return input_ids, attention_masks, token_type_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71523b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(dataset, MAX_LEN):\n",
    "    input_ids, attention_masks, token_type_ids = [], [], []\n",
    "    for each_review in tqdm(dataset['Review']):\n",
    "        input_id, attention_mask, token_type_id = electra_tokenizer(each_review, MAX_LEN)\n",
    "\n",
    "        input_ids.append(input_id)\n",
    "        attention_masks.append(attention_mask)\n",
    "        token_type_ids.append(token_type_id)\n",
    "    \n",
    "    tensordataset = TensorDataset(torch.tensor(input_ids), torch.tensor(attention_masks), torch.tensor(token_type_ids), torch.LongTensor(dataset['Rating'].values).unsqueeze(dim=1))\n",
    "    return tensordataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f616f0eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3ba893335394e82b190c74ae542bde3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/367365 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = make_dataset(train_data, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97bd301b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b503a8fee9147a4b0311f9e829cf2cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45921 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "537c1b2874c449b5a56aef73ae8d5e01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45921 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "valid_dataset = make_dataset(valid_data, 256)\n",
    "test_dataset = make_dataset(test_data, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b8fb179",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "valid_dataloader = DataLoader(valid_dataset) # default: batch_size=1, shuffle=False\n",
    "test_dataloader = DataLoader(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32be5006",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e188fd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint_testing.pt'):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            print(\"\")\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ecacc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3211bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001, weight_decay=5e-6)\n",
    "#loss_fn = torch.nn.CrossEntropyLoss(reduction='sum')\n",
    "epochs = 1000\n",
    "early_stopping = EarlyStopping(patience = 10, verbose = True, path='./koelectra_best_f1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9bdeeeb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112922882"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad) # in BERT, 177854978"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43703d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00b6108a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElectraForSequenceClassification(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(35000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): ElectraClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e3bc66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0  ||  Elapsed: 0:30:16.\n",
      "   Train_loss: 0.1023  ||  Valid_acc: 0.9698 | Valid_f1: 0.9821 | Valid_loss: 0.0857\n",
      "\n",
      "Validation loss decreased (inf --> 0.085708).  Saving model ...\n",
      "\n",
      "EPOCH: 1  ||  Elapsed: 0:30:21.\n",
      "   Train_loss: 0.0723  ||  Valid_acc: 0.9703 | Valid_f1: 0.9824 | Valid_loss: 0.0834\n",
      "\n",
      "Validation loss decreased (0.085708 --> 0.083367).  Saving model ...\n",
      "\n",
      "EPOCH: 2  ||  Elapsed: 0:30:23.\n",
      "   Train_loss: 0.0549  ||  Valid_acc: 0.9705 | Valid_f1: 0.9826 | Valid_loss: 0.0903\n",
      "EarlyStopping counter: 1 out of 10\n",
      "\n",
      "EPOCH: 3  ||  Elapsed: 0:30:23.\n",
      "   Train_loss: 0.0411  ||  Valid_acc: 0.9691 | Valid_f1: 0.9817 | Valid_loss: 0.1057\n",
      "EarlyStopping counter: 2 out of 10\n",
      "\n",
      "EPOCH: 4  ||  Elapsed: 0:30:23.\n",
      "   Train_loss: 0.0326  ||  Valid_acc: 0.9707 | Valid_f1: 0.9827 | Valid_loss: 0.1178\n",
      "EarlyStopping counter: 3 out of 10\n",
      "\n",
      "EPOCH: 5  ||  Elapsed: 0:30:24.\n",
      "   Train_loss: 0.0265  ||  Valid_acc: 0.9704 | Valid_f1: 0.9825 | Valid_loss: 0.1172\n",
      "EarlyStopping counter: 4 out of 10\n",
      "\n",
      "EPOCH: 6  ||  Elapsed: 0:30:23.\n",
      "   Train_loss: 0.0220  ||  Valid_acc: 0.9708 | Valid_f1: 0.9828 | Valid_loss: 0.1140\n",
      "EarlyStopping counter: 5 out of 10\n",
      "\n",
      "EPOCH: 7  ||  Elapsed: 0:30:17.\n",
      "   Train_loss: 0.0193  ||  Valid_acc: 0.9698 | Valid_f1: 0.9822 | Valid_loss: 0.1370\n",
      "EarlyStopping counter: 6 out of 10\n",
      "\n",
      "EPOCH: 8  ||  Elapsed: 0:30:20.\n",
      "   Train_loss: 0.0163  ||  Valid_acc: 0.9690 | Valid_f1: 0.9817 | Valid_loss: 0.1556\n",
      "EarlyStopping counter: 7 out of 10\n",
      "\n",
      "EPOCH: 9  ||  Elapsed: 0:30:19.\n",
      "   Train_loss: 0.0138  ||  Valid_acc: 0.9696 | Valid_f1: 0.9820 | Valid_loss: 0.1497\n",
      "EarlyStopping counter: 8 out of 10\n",
      "\n",
      "EPOCH: 10  ||  Elapsed: 0:30:21.\n",
      "   Train_loss: 0.0122  ||  Valid_acc: 0.9689 | Valid_f1: 0.9816 | Valid_loss: 0.1691\n",
      "EarlyStopping counter: 9 out of 10\n",
      "\n",
      "EPOCH: 11  ||  Elapsed: 0:30:23.\n",
      "   Train_loss: 0.0109  ||  Valid_acc: 0.9680 | Valid_f1: 0.9812 | Valid_loss: 0.1547\n",
      "EarlyStopping counter: 10 out of 10\n",
      "\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "train_loss_list, valid_loss_list, valid_accuracy_list, valid_f1_list = [], [], [], []\n",
    "optimizer.zero_grad()\n",
    "for epoch in range(epochs):\n",
    "    t0 = time.time()\n",
    "    train_pred_list = []\n",
    "    train_loss, valid_loss, valid_accuracy = 0.0, 0.0, 0.0\n",
    "    epoch_loss = 0.0\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    for batch in train_dataloader:\n",
    "        b_input_ids, b_attention_masks, b_token_type_ids, b_labels = tuple(t.to(device) for t in batch)\n",
    "        out = model(b_input_ids, b_attention_masks, b_token_type_ids, labels=b_labels)\n",
    "        loss, logits = out.loss, out.logits\n",
    "        epoch_loss += loss.item()        \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #pred = torch.argmax(F.softmax(logits, dim=0), dim=1).unsqueeze(dim=1).cpu()\n",
    "        #pred_list.append(pred)\n",
    "        #epoch_accuracy += (pred==b_labels).cpu().numpy().mean()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "    train_loss = float(epoch_loss / len(train_dataloader))\n",
    "    #train_accuracy = float(epoch_accuracy / len(train_dataloader))\n",
    "    \n",
    "    train_loss_list.append(train_loss)\n",
    "    #train_accuracy_list.append(train_accuracy)\n",
    "    \n",
    "    valid_pred_list, valid_real_list = [], []\n",
    "    valid_accuracy, valid_f1, epoch_accuracy, epoch_loss = 0.0, 0.0, 0.0, 0.0\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for batch in valid_dataloader:\n",
    "            b_input_ids, b_attention_masks, b_token_type_ids, b_labels = tuple(t.to(device) for t in batch)\n",
    "            out = model(b_input_ids, b_attention_masks, b_token_type_ids, labels=b_labels)\n",
    "            loss, logits = out.loss, out.logits\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            pred = torch.argmax(logits).cpu()\n",
    "            valid_pred_list.append(pred)\n",
    "            valid_real_list.append(b_labels.squeeze(dim=0).squeeze(dim=0).cpu())\n",
    "            #epoch_accuracy += (pred==b_labels).cpu().numpy()\n",
    "            \n",
    "        \n",
    "        valid_loss = float(epoch_loss / len(valid_dataloader))\n",
    "        #valid_accuracy = float(epoch_accuracy / len(valid_dataloader))\n",
    "        valid_accuracy = accuracy_score(valid_real_list, valid_pred_list)\n",
    "        valid_f1 = f1_score(valid_real_list, valid_pred_list)\n",
    "        \n",
    "        valid_loss_list.append(valid_loss)\n",
    "        valid_accuracy_list.append(valid_accuracy)\n",
    "        valid_f1_list.append(valid_f1)\n",
    "\n",
    "        print(f\"EPOCH: {epoch}  ||  Elapsed: {format_time(time.time()-t0)}.\")\n",
    "        print(f\"   Train_loss: {train_loss:.4f}  ||  Valid_acc: {valid_accuracy:.4f} | Valid_f1: {valid_f1:.4f} | Valid_loss: {valid_loss:.4f}\")\n",
    "        \n",
    "        early_stopping(valid_loss, model)\n",
    "        print(\"\")\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d22bfdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.87      0.89      7092\n",
      "           1       0.98      0.99      0.98     38829\n",
      "\n",
      "    accuracy                           0.97     45921\n",
      "   macro avg       0.95      0.93      0.94     45921\n",
      "weighted avg       0.97      0.97      0.97     45921\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(valid_real_list, valid_pred_list)) # 이건 11번째 epoch의 valid 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21980105",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('./koelectra_best_f1.pt'))\n",
    "test_pred_list, test_real_list = [], []\n",
    "test_accuracy, test_f1 = 0.0, 0.0\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for batch in test_dataloader:\n",
    "        b_input_ids, b_attention_masks, b_token_type_ids, b_labels = tuple(t.to(device) for t in batch)\n",
    "        out = model(b_input_ids, b_attention_masks, b_token_type_ids, labels=b_labels)\n",
    "        loss, logits = out.loss, out.logits\n",
    "\n",
    "        pred = torch.argmax(logits).cpu()\n",
    "        test_pred_list.append(pred)\n",
    "        test_real_list.append(b_labels.squeeze(dim=0).squeeze(dim=0).cpu())\n",
    "        \n",
    "    test_accuracy = accuracy_score(test_real_list, test_pred_list)\n",
    "    test_f1 = f1_score(test_real_list, test_pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1453049b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_acc: 0.9696 | Test_f1: 0.9820\n"
     ]
    }
   ],
   "source": [
    " print(f\"Test_acc: {test_accuracy:.4f} | Test_f1: {test_f1:.4f}\") # 이건 best epoch(=2)의 test 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b8947c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.90      7093\n",
      "           1       0.98      0.98      0.98     38828\n",
      "\n",
      "    accuracy                           0.97     45921\n",
      "   macro avg       0.94      0.94      0.94     45921\n",
      "weighted avg       0.97      0.97      0.97     45921\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_real_list, test_pred_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cf0500",
   "metadata": {},
   "source": [
    "train 시 vram 13785 소요"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f6659004ad2638910e883307224ae22216d48c1d40318e5d7c09413d906fa99a"
  },
  "kernelspec": {
   "display_name": "dacon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
